



resource "aws_lb_target_group" "private_ip_pool_metallb" {
  name        = "private-ip-pool-metallb"
  port        = 80
  protocol    = "HTTP"
  target_type = "ip"
  vpc_id      = aws_vpc.konvoy_vpc.id
}



resource "aws_lb" "konvoy_workload_lb" {
  name                      = "konvoy-workload-lb"
  internal                  = false
  load_balancer_type        = "application"
  security_groups           = [aws_security_group.konvoy_private.id, aws_security_group.konvoy_metallb_ip.id]
  subnets                   = [for subnet in aws_subnet.konvoy_subnets: subnet.id]


  tags = var.tags
}
resource "aws_lb_listener" "workload_lb" {
  load_balancer_arn = aws_lb.konvoy_workload_lb.arn
  port              = "80"
  protocol          = "HTTP"

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.private_ip_pool_metallb.arn
  }
}

resource "aws_lb_target_group_attachment" "attach_workload_target_group" {
  target_group_arn = aws_lb_target_group.private_ip_pool_metallb.arn
  target_id        = "10.0.255.224"
  port             = 80
}


output "vpc_cidr" {
  value = aws_vpc.konvoy_vpc.cidr_block
}

output "workload_lb"{
  value = aws_lb.konvoy_workload_lb.dns_name
}


resource "aws_instance" "control_plane" {
  count                       = 1
  vpc_security_group_ids      = [aws_security_group.konvoy_ssh.id, aws_security_group.konvoy_private.id, aws_security_group.konvoy_egress.id]
  subnet_id                   = "${aws_subnet.konvoy_subnets[0].id}"
  key_name                    = var.ssh_key_name
  ami                         = var.node_ami
  instance_type               = var.control_plane_instance_type
  availability_zone           = "${var.aws_availability_zones[0]}"
  source_dest_check           = "false"
  associate_public_ip_address = "true"

  tags = var.tags

  root_block_device {
    volume_size = var.root_volume_size
  }

  provisioner "remote-exec" {
    inline = [
      "echo ok"
    ]

    connection {
      type = "ssh"
      user = var.ssh_username
      agent = true
      host = self.public_dns
      timeout = "15m"
    }
  }
}

resource "aws_instance" "worker" {
  count                       = var.worker_count
  vpc_security_group_ids      = [aws_security_group.konvoy_ssh.id, aws_security_group.konvoy_private.id, aws_security_group.konvoy_egress.id]
  subnet_id                   = "${aws_subnet.konvoy_subnets[0].id}"
  key_name                    = var.ssh_key_name
  ami                         = var.node_ami
  instance_type               = var.worker_instance_type
  availability_zone           = "${var.aws_availability_zones[0]}"
  source_dest_check           = "false"
  associate_public_ip_address = "true"

  tags = var.tags

  root_block_device {
    volume_size = var.root_volume_size
  }

  provisioner "remote-exec" {
    inline = [
      "echo ok"
    ]

    connection {
      type = "ssh"
      user = var.ssh_username
      agent = true
      host = self.public_dns
      timeout = "15m"
    }
  }
}

resource "aws_instance" "extra_worker" {
  count                       = var.extra_worker_count
  vpc_security_group_ids      = [aws_security_group.konvoy_ssh.id, aws_security_group.konvoy_private.id, aws_security_group.konvoy_egress.id]
  subnet_id                   = "${aws_subnet.konvoy_subnets[0].id}"
  key_name                    = var.ssh_key_name
  ami                         = var.node_ami
  instance_type               = var.extra_worker_instance_type
  availability_zone           = "${var.aws_availability_zones[0]}"
  source_dest_check           = "false"
  associate_public_ip_address = "true"

  tags = var.tags

  root_block_device {
    volume_size = var.root_volume_size
  }

  provisioner "remote-exec" {
    inline = [
      "echo ok"
    ]

    connection {
      type = "ssh"
      user = var.ssh_username
      agent = true
      host = self.public_dns
      timeout = "15m"
    }
  }
}

resource "aws_security_group" "konvoy_control_plane" {
  description = "Allow inbound kubectl to controlplane."
  vpc_id      = aws_vpc.konvoy_vpc.id

  ingress {
    from_port   = 6443
    to_port     = 6443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = var.tags
}

resource "aws_elb" "konvoy_control_plane" {
  internal                  = false
  security_groups           = [aws_security_group.konvoy_private.id, aws_security_group.konvoy_control_plane.id]
  subnets                   = [aws_subnet.konvoy_subnets[0].id]
  connection_draining       = true
  cross_zone_load_balancing = true


  health_check {
    healthy_threshold   = 2
    unhealthy_threshold = 2
    timeout             = 3
    target              = "HTTPS:6443/healthz"
    interval            = 10
  }

  listener {
    instance_port     = 6443
    instance_protocol = "tcp"
    lb_port           = 6443
    lb_protocol       = "tcp"
  }

  instances = aws_instance.control_plane.*.id

  tags = var.tags
}


resource "aws_security_group" "konvoy_metallb_ip" {
  description = "Allow inbound to metallb target."
  vpc_id      = aws_vpc.konvoy_vpc.id

  ingress {
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }  

  tags = var.tags
}


output "kube_apiserver_address" {
  value = aws_elb.konvoy_control_plane.dns_name
}

output "control_plane_public_ips" {
  value = aws_instance.control_plane.*.public_ip
}

output "worker_public_ips" {
  value = aws_instance.worker.*.public_ip
}

output "extra_worker_public_ips" {
  value = aws_instance.extra_worker.*.public_ip
}